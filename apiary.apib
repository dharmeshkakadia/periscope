FORMAT: 1A
# Periscope

![SequenceIQ](https://raw.githubusercontent.com/sequenceiq/sequenceiq.github.io/master/img/logo.png)

*Periscope is a powerful, fast, thick and top-to-bottom right-hander, eastward from Sumbawa's famous west-coast. Timing is critical, as needs a number of elements to align before it shows its true colors.*

*Periscope is a heuristic Hadoop scheduler you associate with a QoS profile. Built on YARN schedulers, cloud and VM resource management API's it allows you to associate SLA's to applications and customers.*

## Overview

The purpose of Periscope is to bring QoS to a multi-tenant Hadoop cluster, while allowing to apply SLA's to individual applications and customers.
At [SequenceIQ](http://sequenceiq.com) working with multi-tenant Hadoop clusters for quite a while we have always seen the same frustration and fight for resource between users.
The **FairScheduler** was partially solving this problem - bringing in fairness based on the notion of [Dominant Resource Fairness](http://static.usenix.org/event/nsdi11/tech/full_papers/Ghodsi.pdf).
With the emergence of Hadoop 2 YARN and the **CapacityScheduler** we had the option to maximize throughput and the utilization of the cluster for a multi-tenant cluster in an operator-friendly manner.
The scheduler works around the concept of queues. These queues are typically setup by administrators to reflect the economics of the shared cluster.
While there is a pretty good abstraction and brings some level of SLA for `predictable` workloads, it often needs proper `design ahead`.
The queue hierarchy and resource allocation needs to be changed when new tenants and workloads are moved to the cluster.

Periscope was designed around the idea of `dynamic` clusters - without any need to preconfigure queues, cluster nodes or apply capacity planning ahead.

## How it works

Periscope monitors the application progress, the number of YARN containers/resources and their allocation on nodes, queue depths, and the number of nodes and their health.
Since we have switched to YARN a while ago (been among the first adopters) we have run an open source [monitoring project](https://github.com/sequenceiq/yarn-monitoring), based on R.
We have been collecting metrics from the YARN Timeline server, Hadoop Metrics2 and Ambari's Nagios/Ganglia - and profiling applications and correlating with these metrics.
One of the key findings we have found - and have applied to Periscope - was that while low level metrics are good to understand the cluster health - they might not necessarily help on making decisions when applying different SLA's on a multi-tenant cluster.
Focusing on higher level building blocks as queue depth, YARN containers, etc actually brings in the same quality of service, while not being lost in low level details.
We will follow up with examples and metrics on coming blog posts - make sure you follow us on [LinkedIn](https://www.linkedin.com/company/sequenceiq/), [Twitter](https://twitter.com/sequenceiq) or [Facebook](https://www.facebook).

_Example: Applying SLA based on `resource` load might not be the best solution - each application tasks generates different loads, and a CPU heavy reduce step might be followed by an I/O heavy mapper - making a decision based on a low `snapshot` might not be the right option.
Also note that a YARN cluster can run different applications - MR2, HBase, Spark, etc - and they all generate different load across different timeframes.
When YARN allocates containers it associates `resources` - it's actually more predictable to let YARN to deal with the resource allocation, and have Periscope orchestrate the process._

Periscope works with two types of Hadoop clusters: `static` and `dynamic`.

### Static clusters
From Periscope point of view we consider a cluster static when the cluster capacity can't be increased horizontally.
This means that the hardware resources are already given - and the throughput can't be increased by adding new nodes.
Periscope introspects the job submission process, monitors the applications and applies the following SLA's:

  1. Application ordering - can guaranty that a higher priority application finishes before another one (supporting parallel or sequential execution)
  2. Moves running applications between priority queues
  3. *Attempts* to enforce time based SLA (execution time, finish by, finish between, recurring)
  4. *Attempts* to enforce guaranteed cluster capacity requests ( x % of the resources)
  5. Support for distributed (but not YARN ready) applications using Apache Slider

### Dynamic clusters
From Periscope point of view we consider a cluster dynamic when the cluster capacity can be increased horizontally.
This means that nodes can be added dynamically - thus the throughput can be increased or decreased based on the cluster load, and scheduled applications.
In order to do that Periscope instructs [Cloudbreak](http://sequenceiq.com/cloudbreak/) to add or remove nodes from the cluster based on the SLA's, load and thus continuously provide a high *quality of service* for the multi-tenand Hadoop cluster.
Just to refresh memories - [Cloudbreak](http://sequenceiq.com/products.html) is [SequenceIQ's](http://sequenceiq.com) open source, cloud agnostic Hadoop as a Service API.
Given the option of provisioning or decommissioning cluster nodes on the fly, Periscope allows you to use the following set of SLA's:

  1. Application ordering - can guaranty that a higher priority application finishes before another one (supporting parallel or sequential execution)
  2. Moves running applications between priority queues
  3. *Enforce* time based SLA (execution time, finish by, finish between, recurring) by increasing cluster capacity and throughput
  4. Smart decommissioning - avoids HDFS storms, keeps `payed` nodes alive till the last minute
  5. *Enforce* guaranteed cluster capacity requests ( x % of the resources)
  6. *Private* cluster requests - supports provisioning of short lived private clusters with the possibility to merge
  7. Support for distributed (but not YARN ready) applications using Apache Slider

#Group Clusters
Clusters related resources of the **Periscope API**.

##Clusters [/clusters/{id}]
###Add a cluster [POST]
Add a cluster to be monitored by Periscope.

+ Parameters
    + id (required String `id`) ... The id of the cluster to be monitored.

+ Request (application/json)

        {
            "host": "172.24.0.2",
            "port": "8080",
            "user": "admin",
            "pass": "admin"
        }

+ Response 201 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }


##  Clusters [/clusters/{id}]
###Retrieved the monitored cluster information [GET]

+ Parameters
    + id (required String `id`) ... The id of the cluster.

+ Request
        {

        }

+ Response 200 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }

##  Clusters [/clusters/{id}]
###Delete the monitored cluster from Periscope [DELETE]

+ Parameters
    + id (required String `id`) ... The id of the cluster.

+ Request
        {

        }

+ Response 200 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }

## Clusters [/clusters/{clusterId}/state]
###Set the state of a cluster [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "state": "SUSPENDED"
        }

+  Response 200 (application/json)

        {
            "appMovement": "prohibited",
            "state": "SUSPENDED",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }

## Clusters [/clusters/{clusterId}/movement]
###Configure application movements within a cluster [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "allowed": "false"
        }

+  Response 200 (application/json)

        {
            "appMovement": "prohibited",
            "state": "SUSPENDED",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }

##  Clusters [/clusters]
###Retrieved all the monitored cluster information [GET]

+ Request
        {

        }

+ Response 200 (application/json)

        [
          {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
          }
        ]

#Group Alarms
Metric alarms.

##Alarm [/clusters/{clusterId}/alarms]
###Create an alarm for a cluster [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "alarms": [
            {
              "alarmName": "pendingContainerHigh",
              "description": "Number of pending containers is high",
              "metric": "PENDING_CONTAINERS",
              "threshold": 10,
              "comparisonOperator": "GREATER_THAN",
              "period": 10
            },
            {
              "alarmName": "freeGlobalResourcesRateLow",
              "description": "Low free global resource rate",
              "metric": "GLOBAL_RESOURCES",
              "threshold": 1,
              "comparisonOperator": "EQUALS",
              "period": 10
            }
          ]
        }

+ Response 200 (application/json)

       {
         "alarms": [
           {
             "scalingPolicyId": null,
             "period": 10,
             "comparisonOperator": "GREATER_THAN",
             "threshold": 10,
             "metric": "PENDING_CONTAINERS",
             "description": "Number of pending containers is high",
             "alarmName": "pendingContainerHigh",
             "id": 50
           },
           {
             "scalingPolicyId": null,
             "period": 10,
             "comparisonOperator": "EQUALS",
             "threshold": 1,
             "metric": "GLOBAL_RESOURCES",
             "description": "Low free global resource rate",
             "alarmName": "freeGlobalResourcesRateLow",
             "id": 51
           }
         ]
       }


##Alarm [/clusters/{clusterId}/alarms]
###Get the alarms for a cluster [GET]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster to attach the policy.

+ Request (application/json)
        {

        }

+ Response 200 (application/json)

        {
          "alarms": [
            {
              "scalingPolicyId": null,
              "period": 10,
              "comparisonOperator": "GREATER_THAN",
              "threshold": 10,
              "metric": "PENDING_CONTAINERS",
              "description": "Number of pending containers is high",
              "alarmName": "pendingContainerHigh",
              "id": 50
            },
            {
              "scalingPolicyId": null,
              "period": 10,
              "comparisonOperator": "EQUALS",
              "threshold": 1,
              "metric": "GLOBAL_RESOURCES",
              "description": "Low free global resource rate",
              "alarmName": "freeGlobalResourcesRateLow",
              "id": 51
            }
          ]
        }

##Alarm [/clusters/{clusterId}/alarms/{alarmId}]
###Delete an alarm from cluster [DELETE]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.
    + alarmId (required String `alarmId`) ... The id of the alarm.

+ Request (application/json)
        {

        }

+ Response 200 (application/json)

        {
          "alarms": [
            {
              "scalingPolicyId": null,
              "period": 10,
              "comparisonOperator": "EQUALS",
              "threshold": 1,
              "metric": "GLOBAL_RESOURCES",
              "description": "Low free global resource rate",
              "alarmName": "freeGlobalResourcesRateLow",
              "id": 51
            }
          ]
        }

#Group Scaling Policy
Scaling policies related to alarms.

##Policy [/clusters/{clusterId}/policies]
###Create a scaling policy. [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "minSize": 2,
          "maxSize": 10,
          "cooldown": 35,
          "scalingPolicies": [
            {
              "name": "downScaleWhenHighResource",
              "adjustmentType": "NODE_COUNT",
              "scalingAdjustment": -2,
              "alarmId": "51"
            },
            {
              "name": "upScaleWhenHighPendingContainers",
              "adjustmentType": "PERCENTAGE",
              "scalingAdjustment": 40,
              "alarmId": "50"
            }
          ]
        }

+ Response 200 (application/json)

        {
          "cooldown": 35,
          "scalingPolicies": [
            {
              "alarmId": 50,
              "scalingAdjustment": 40,
              "adjustmentType": "PERCENTAGE",
              "name": "upScaleWhenHighPendingContainers",
              "id": 101
            },
            {
              "alarmId": 51,
              "scalingAdjustment": -2,
              "adjustmentType": "NODE_COUNT",
              "name": "downScaleWhenHighResource",
              "id": 100
            }
          ],
          "maxSize": 10,
          "minSize": 2
        }

##Policy [/clusters/{clusterId}/policies]
###List the scaling policies. [GET]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {

        }

+ Response 200 (application/json)

        {
          "cooldown": 35,
          "scalingPolicies": [
            {
              "alarmId": 50,
              "scalingAdjustment": 40,
              "adjustmentType": "PERCENTAGE",
              "name": "upScaleWhenHighPendingContainers",
              "id": 101
            },
            {
              "alarmId": 51,
              "scalingAdjustment": -2,
              "adjustmentType": "NODE_COUNT",
              "name": "downScaleWhenHighResource",
              "id": 100
            }
          ],
          "maxSize": 10,
          "minSize": 2
        }

##Policy [/clusters/{clusterId}/policies/{policyId}]
###Delete a scaling policy. [DELETE]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.
    + policyId (required String `policyId`) ... The id of the policy.

+ Request (application/json)

        {

        }

+ Response 200 (application/json)

        {
          "cooldown": 35,
          "scalingPolicies": [
            {
              "alarmId": 50,
              "scalingAdjustment": 40,
              "adjustmentType": "PERCENTAGE",
              "name": "upScaleWhenHighPendingContainers",
              "id": 101
            }
          ],
          "maxSize": 10,
          "minSize": 2
        }

#Group Applications
Applications related resources of the **Periscope API**.

##Applications [/clusters/{clusterId}/applications]
###List the running applications in a cluster [GET]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {

        }

+ Response 200 (application/json)

        [
            {
                "usedVCores": 1,
                "usedMemory": 512,
                "reservedContainers": 0,
                "usedContainers": 1,
                "appId": "application_1407836063840_0001",
                "user": "hdfs",
                "queue": "default",
                "state": "ACCEPTED",
                "url": "http://amb0.mycorp.kom:8088/proxy/application_1407836063840_0001/",
                "start": 1407847270776,
                "finish": 0,
                "progress": 0
              }
        ]

#Group Configuration
Configuration related resources of the **Periscope API**.

##Configuration [/clusters/{clusterId}/configurations]
###Reload the HADOOP configuration [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {

        }

+ Response 200 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "multi-node"
        }

##Configuration [/clusters/{clusterId}/configurations/queue]
###Reconfigure the queue capacities [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "setup": [
            {
              "name": "default",
              "capacity": 55
            },
            {
              "name": "high",
              "capacity": 45
            }
          ]
        }

+ Response 200 (application/json)

        {
          "properties": {
            "yarn.scheduler.capacity.root.capacity": "100",
            "yarn.scheduler.capacity.root.high.maximum-capacity": "45",
            "yarn.scheduler.capacity.root.default.user-limit-factor": "1",
            "yarn.scheduler.capacity.root.high.user-limit-factor": "1",
            "yarn.scheduler.capacity.root.default.acl_submit_applications": "*",
            "yarn.scheduler.capacity.maximum-am-resource-percent": "0.2",
            "yarn.scheduler.capacity.root.high.state": "RUNNING",
            "yarn.scheduler.capacity.root.default.maximum-capacity": "55",
            "yarn.scheduler.capacity.node-locality-delay": "40",
            "yarn.scheduler.capacity.root.default.acl_administer_jobs": "*",
            "yarn.scheduler.capacity.root.queues": "default,high",
            "yarn.scheduler.capacity.root.default.state": "RUNNING",
            "yarn.scheduler.capacity.root.unfunded.capacity": "50",
            "yarn.scheduler.capacity.root.high.acl_administer_jobs": "*",
            "yarn.scheduler.capacity.root.acl_administer_queue": "*",
            "yarn.scheduler.capacity.root.high.acl_submit_applications": "*",
            "yarn.scheduler.capacity.root.high.capacity": "45",
            "yarn.scheduler.capacity.maximum-applications": "9999",
            "yarn.scheduler.capacity.root.default.capacity": "55"
          },
          "setup": [
            {
              "capacity": 55,
              "name": "default"
            },
            {
              "capacity": 45,
              "name": "high"
            }
          ]
        }
